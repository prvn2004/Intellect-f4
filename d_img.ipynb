{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "import multiprocessing\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "INPUT_CSV = 'test.csv'\n",
    "OUTPUT_CSV = 'test_data.csv'\n",
    "IMAGE_DIR = './test_images/'\n",
    "BATCH_SIZE = 100  # Batch size for processing images\n",
    "\n",
    "def create_placeholder_image(image_save_path):\n",
    "    \"\"\"Create a placeholder image in case the image download fails.\"\"\"\n",
    "    try:\n",
    "        placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
    "        placeholder_image.save(image_save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create placeholder image: {e}\")\n",
    "\n",
    "def download_image(image_link, index, save_folder, retries=3, delay=3):\n",
    "    \"\"\"Download a single image, retry if it fails, and create a placeholder image if all retries fail.\"\"\"\n",
    "    if not isinstance(image_link, str):\n",
    "        return\n",
    "\n",
    "    filename = f\"{index}.jpg\"  # Use the original index from the DataFrame\n",
    "    image_save_path = os.path.join(save_folder, filename)\n",
    "\n",
    "    if os.path.exists(image_save_path):\n",
    "        return\n",
    "\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(image_link, image_save_path)\n",
    "            return\n",
    "        except:\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    create_placeholder_image(image_save_path)\n",
    "\n",
    "def download_images(image_links, indices, download_folder, allow_multiprocessing=True):\n",
    "    \"\"\"Download images from a list of links, using multiprocessing if allowed.\"\"\"\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    if allow_multiprocessing:\n",
    "        download_image_partial = partial(\n",
    "            download_image, save_folder=download_folder, retries=3, delay=3)\n",
    "\n",
    "        with multiprocessing.Pool(64) as pool:\n",
    "            list(tqdm(pool.starmap(download_image_partial, zip(image_links, indices)), total=len(image_links)))\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "    else:\n",
    "        for image_link, index in tqdm(zip(image_links, indices), total=len(image_links)):\n",
    "            download_image(image_link, index, save_folder=download_folder, retries=3, delay=3)\n",
    "\n",
    "def process_images(df, start_index):\n",
    "    os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "    images_data = []\n",
    "\n",
    "    image_links = df['image_link'].tolist()\n",
    "    indices = df.index.tolist()  # Use DataFrame's original index\n",
    "\n",
    "    download_images(image_links, indices, IMAGE_DIR, allow_multiprocessing=True)\n",
    "\n",
    "    for row in tqdm(df.itertuples(), desc='Processing Images', unit='img', ncols=100, leave=False):\n",
    "        index = row.Index  # Correct way to get the original index\n",
    "        image_path = os.path.join(IMAGE_DIR, f\"{index}.jpg\")  # Name image using original index\n",
    "\n",
    "        images_data.append({\n",
    "            'index': index,  # Append the original index to images_data\n",
    "            'image_path': image_path,\n",
    "            'user_input': f\"extract the {row.entity_name} from given image\",\n",
    "        })\n",
    "    \n",
    "    return images_data\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(INPUT_CSV, index_col=0)  # Ensure index column is used\n",
    "    if os.path.exists(OUTPUT_CSV):\n",
    "        existing_df = pd.read_csv(OUTPUT_CSV)\n",
    "        last_index = existing_df['index'].max() if not existing_df.empty else -1\n",
    "        start_index = df[df.index > last_index].index.min() if last_index >= 0 else 0\n",
    "    else:\n",
    "        start_index = 0\n",
    "    \n",
    "    total_images = len(df) - start_index\n",
    "    if total_images <= 0:\n",
    "        print(\"No new images to process.\")\n",
    "        return\n",
    "\n",
    "    num_batches = (total_images + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    with tqdm(total=num_batches, desc='Processing Batches', ncols=100, unit='batch') as batch_progress:\n",
    "        for batch_start in range(start_index, len(df), BATCH_SIZE):\n",
    "            batch_end = min(batch_start + BATCH_SIZE, len(df))\n",
    "            batch_df = df.iloc[batch_start:batch_end]\n",
    "            \n",
    "            images_data = process_images(batch_df, batch_start)\n",
    "\n",
    "            batch_df_output = pd.DataFrame(images_data)\n",
    "            if os.path.exists(OUTPUT_CSV):\n",
    "                batch_df_output.to_csv(OUTPUT_CSV, mode='a', header=False, index=False)\n",
    "            else:\n",
    "                batch_df_output.to_csv(OUTPUT_CSV, mode='w', header=True, index=False)\n",
    "            \n",
    "            batch_progress.update(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
