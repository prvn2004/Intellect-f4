{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "from util.vision_util import process_vision_info\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "model_dir = \"train_output/20240915191425/\"\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_dir, torch_dtype=\"auto\", device_map=\"auto\"\n",
    ").half()  # Use mixed precision if supported\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_dir, padding_side=\"left\")\n",
    "\n",
    "# Load and preprocess data\n",
    "with open('output_test.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "messages = []\n",
    "results = []\n",
    "\n",
    "for message_obj in data:\n",
    "    try:\n",
    "        image_path = message_obj['messages'][0]['content'][0]['image']\n",
    "        text_instruction = f\"Extract only the value of {message_obj['messages'][0]['content'][1]['text'].split(' ')[2]} with its unit from the given image, without any extra details.\"\n",
    "\n",
    "        message = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image_path},\n",
    "                {\"type\": \"text\", \"text\": text_instruction}\n",
    "            ]\n",
    "        }]\n",
    "        messages.append(message)\n",
    "    except (IndexError, KeyError, ValueError) as e:\n",
    "        print(f\"Skipping message due to error: {e}\")\n",
    "\n",
    "# Load existing results\n",
    "csv_file = 'result.csv'\n",
    "if os.path.exists(csv_file):\n",
    "    processed_df = pd.read_csv(csv_file)\n",
    "    processed_images = set(processed_df['index'].tolist())\n",
    "else:\n",
    "    processed_df = pd.DataFrame(columns=['index', 'prediction'])\n",
    "    processed_images = set()\n",
    "\n",
    "def process_batch(batch_messages):\n",
    "    batch_results = []\n",
    "    image_inputs, video_inputs = process_vision_info(batch_messages)\n",
    "\n",
    "    if image_inputs:\n",
    "        texts = [processor.apply_chat_template(msg, tokenize=False, add_generation_prompt=True) for msg in batch_messages]\n",
    "        inputs = processor(\n",
    "            text=texts,\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(\"cpu\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "            generated_ids_trimmed = [out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
    "            output_text = processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True)\n",
    "\n",
    "            for idx, message in enumerate(batch_messages):\n",
    "                image_path = message[0]['content'][0]['image']\n",
    "                prediction = output_text[idx]\n",
    "                batch_results.append({'index': image_path, 'prediction': prediction})\n",
    "\n",
    "    return batch_results\n",
    "\n",
    "batch_size = 2\n",
    "all_results = []\n",
    "\n",
    "# Define index range to process\n",
    "x = 0  # Set starting index\n",
    "y = 25000  # Set ending index (or any specific index you want)\n",
    "\n",
    "unprocessed_messages = [msg for msg in messages[x:y] if msg[0]['content'][0]['image'] not in processed_images]\n",
    "\n",
    "for i in tqdm(range(0, len(unprocessed_messages), batch_size), desc=\"Processing Batches\"):\n",
    "    batch_messages = unprocessed_messages[i:i + batch_size]\n",
    "    batch_results = process_batch(batch_messages)\n",
    "    all_results.extend(batch_results)\n",
    "\n",
    "    if batch_results:\n",
    "        batch_df = pd.DataFrame(batch_results)\n",
    "        batch_df.to_csv(csv_file, mode='a', header=not os.path.exists(csv_file), index=False)\n",
    "\n",
    "df = pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "csv_file = 'result.csv'  # Replace with your CSV filename\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Define the function to strip the path and file extension\n",
    "def modify_index(index_value):\n",
    "    return index_value.split('/')[-1].replace('.jpg', '')\n",
    "\n",
    "# Apply the function to the first column (assuming it's named 'index')\n",
    "df['index'] = df['index'].apply(modify_index)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV\n",
    "output_file = 'modified_file.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Modified file saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "test_df = pd.read_csv('test.csv')\n",
    "modified_df = pd.read_csv('modified_file.csv')\n",
    "\n",
    "# Merge the dataframes based on 'index' column, keeping all rows from test_df\n",
    "merged_df = pd.merge(test_df[['index']], modified_df[['index', 'prediction']], on='index', how='left')\n",
    "\n",
    "# Fill NaN values in the 'prediction' column with an empty string\n",
    "merged_df['prediction'].fillna('', inplace=True)\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "merged_df.to_csv('final_output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define a function to extract the numeric value and preserve the unit\n",
    "def extract_and_preserve(value):\n",
    "    # Extract the numeric part and the unit from the value\n",
    "    match = re.match(r\"([-+]?\\d*\\.\\d+|\\d+)\\s*(.*)\", str(value))\n",
    "    if match:\n",
    "        numeric_value = float(match.group(1))\n",
    "        unit = match.group(2).strip()\n",
    "        return f\"{numeric_value} {unit}\"\n",
    "    return value  # Return the original value if extraction fails\n",
    "\n",
    "# Load the CSV file and process it\n",
    "def process_csv(file_path):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Apply the extraction and preservation to the 'prediction' column\n",
    "    df['prediction'] = df['prediction'].apply(extract_and_preserve)\n",
    "\n",
    "    # Save the modified DataFrame to a new CSV file\n",
    "    output_file = file_path.replace(\".csv\", \"_processed.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Processing complete! File saved as {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = \"final_output.csv\"  # Replace with your actual CSV file path\n",
    "process_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the entity-unit map and allowed units\n",
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
    "}\n",
    "\n",
    "allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('final_output_processed.csv', header=None, names=['id', 'value'])\n",
    "\n",
    "# Define a function to process units\n",
    "def process_unit(value):\n",
    "    value_str = str(value)  # Convert the value to string\n",
    "    for unit in allowed_units:\n",
    "        if unit.lower() in value_str.lower():\n",
    "            return value_str  # Return the original value if unit is valid\n",
    "    # If unit is not valid, default to 'inch'\n",
    "    return value_str.split()[0] + ' inch'\n",
    "\n",
    "# Apply the function to the 'value' column\n",
    "df['value'] = df['value'].apply(process_unit)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('updated_final.csv', index=False, header=False)\n",
    "\n",
    "print(\"Units updated and saved to 'updated_final.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the entity-unit map and allowed units\n",
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
    "}\n",
    "\n",
    "allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('updated_final.csv', header=None, names=['id', 'value'])\n",
    "\n",
    "# Define a function to extract and validate the unit\n",
    "def process_unit(value):\n",
    "    value_str = str(value)\n",
    "    \n",
    "    # Extract potential unit from value\n",
    "    match = re.search(r'([a-zA-Z\\s]+)$', value_str)\n",
    "    if match:\n",
    "        extracted_unit = match.group(1).strip().lower()\n",
    "        \n",
    "        # Check if the extracted unit is valid\n",
    "        if extracted_unit in allowed_units:\n",
    "            return value_str\n",
    "        \n",
    "    # If unit is not valid or not found, default to 'inch'\n",
    "    default_unit = 'inch'\n",
    "    # Extract numerical part\n",
    "    numerical_part = re.match(r'^[\\d\\.\\[\\],\\s]+', value_str)\n",
    "    if numerical_part:\n",
    "        return numerical_part.group().strip() + ' ' + default_unit\n",
    "    else:\n",
    "        return '0 ' + default_unit\n",
    "\n",
    "# Apply the function to the 'value' column\n",
    "df['value'] = df['value'].apply(process_unit)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('updated_final.csv', index=False, header=False)\n",
    "\n",
    "print(\"Units updated and saved to 'updated_final.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the entity-unit map and allowed units\n",
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
    "}\n",
    "\n",
    "allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('updated_final.csv', header=None, names=['id', 'value'])\n",
    "\n",
    "# Define a function to process each entry\n",
    "def process_entry(value):\n",
    "    value_str = str(value)\n",
    "    \n",
    "    # Extract numerical value\n",
    "    numerical_match = re.match(r'[\\d\\.]+', value_str)\n",
    "    if numerical_match:\n",
    "        numerical_value = float(numerical_match.group())\n",
    "    else:\n",
    "        numerical_value = 0.0  # Default to 0 if no numerical value is found\n",
    "    \n",
    "    # Extract unit\n",
    "    unit_match = re.search(r'([a-zA-Z\\s]+)$', value_str)\n",
    "    if unit_match:\n",
    "        extracted_unit = unit_match.group().strip().lower()\n",
    "        if extracted_unit in allowed_units:\n",
    "            return f\"{numerical_value} {extracted_unit}\"\n",
    "    \n",
    "    # Default to 'inch' if unit is not valid or not found\n",
    "    default_unit = 'inch'\n",
    "    return f\"{numerical_value} {default_unit}\"\n",
    "\n",
    "# Apply the function to the 'value' column\n",
    "df['value'] = df['value'].apply(process_entry)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('updated_final.csv', index=False, header=False)\n",
    "\n",
    "print(\"Units updated and saved to 'updated_final.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "updated_df = pd.read_csv('updated_final.csv', header=None, names=['index', 'value'])\n",
    "test_df = pd.read_csv('test.csv', header=None, names=['index', 'value'])\n",
    "\n",
    "# Convert 'index' columns to ensure proper matching\n",
    "updated_df['index'] = updated_df['index'].astype(str)\n",
    "test_df['index'] = test_df['index'].astype(str)\n",
    "\n",
    "# Find indexes present in updated_final.csv but not in test.csv\n",
    "indexes_in_updated_not_in_test = set(updated_df['index']) - set(test_df['index'])\n",
    "\n",
    "# Filter rows in updated_final.csv based on indexes\n",
    "filtered_df = updated_df[~updated_df['index'].isin(indexes_in_updated_not_in_test)]\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "filtered_df.to_csv('filtered_updated_final.csv', index=False, header=False)\n",
    "\n",
    "print(\"Filtered data saved to 'updated_final.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
